{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AahladKarthik/Aquanos/blob/main/Algo_Trading_System_with_ML_%26_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOUNTED GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "gH8Bo1BQO6QV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nda8qjnqNoH4",
        "outputId": "677d6554-1a18-440d-88b7-706511c4c0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING PROJECT DIRECTORY STRUCTURE"
      ],
      "metadata": {
        "id": "AKF-zls0PBTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Project Directory Structure\n",
        "import os\n",
        "\n",
        "# Defining the project root in Google Drive\n",
        "project_root = '/content/drive/MyDrive/algo_trading_prototype'\n",
        "\n",
        "# Creating the main project directory\n",
        "os.makedirs(project_root, exist_ok=True)\n",
        "print(f\"Project root created: {project_root}\")\n",
        "\n",
        "# Creating subdirectories\n",
        "subdirectories = [\n",
        "    'config',\n",
        "    'data',\n",
        "    'strategy',\n",
        "    'backtester',\n",
        "    'analytics',\n",
        "    'sheets',\n",
        "    'utils',\n",
        "    'logs' # Directory for log files\n",
        "]\n",
        "\n",
        "for subdir in subdirectories:\n",
        "    path = os.path.join(project_root, subdir)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    print(f\"Created directory: {path}\")\n",
        "\n",
        "# I have added __init__.py files to make directories into Python packages\n",
        "# This is crucial for Python to recognize the folders as modules for importing.\n",
        "\n",
        "for pkg_dir in ['data', 'strategy', 'backtester', 'analytics', 'sheets', 'utils']:\n",
        "    with open(os.path.join(project_root, pkg_dir, '__init__.py'), 'w') as f:\n",
        "        pass # Created an empty __init__.py file\n",
        "    print(f\"Created __init__.py in {pkg_dir}\")\n",
        "\n",
        "print(\"\\nDirectory structure created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1SjuFktOJoK",
        "outputId": "c4e6713e-98cf-4f8f-b243-62e36148f48c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root created: /content/drive/MyDrive/algo_trading_prototype\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/config\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/data\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/strategy\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/backtester\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/analytics\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/sheets\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/utils\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/logs\n",
            "Created __init__.py in data\n",
            "Created __init__.py in strategy\n",
            "Created __init__.py in backtester\n",
            "Created __init__.py in analytics\n",
            "Created __init__.py in sheets\n",
            "Created __init__.py in utils\n",
            "\n",
            "Directory structure created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALLING THE DEPENDENCIES"
      ],
      "metadata": {
        "id": "7MvCiRG1QMSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the Dependencies\n",
        "# Used --quiet to suppress verbose output\n",
        "!pip install --no-cache-dir gspread google-auth google-auth-oauthlib google-api-python-client\n",
        "!pip install pandas numpy ta gspread oauth2client scikit-learn requests yfinance python-telegram-bot\n",
        "print(\"All required Python dependencies installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzg7TpdmPLt5",
        "outputId": "b2cef514-3dfb-42e8-918a-a8f986bac994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.177.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-22.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->oauth2client) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (1.3.1)\n",
            "Downloading python_telegram_bot-22.3-py3-none-any.whl (717 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.1/717.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=3c717244e8b7654e11258e9499348a2a1260521a59e4d03cdaaa0787b79010b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta, python-telegram-bot\n",
            "Successfully installed python-telegram-bot-22.3 ta-0.11.0\n",
            "All required Python dependencies installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOLDS ALL CONFIGURATIONS"
      ],
      "metadata": {
        "id": "64ow2GkpQ75m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: config/settings.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/config/settings.py\n",
        "# config/settings.py\n",
        "\n",
        "# Stock Data API (using yfinance)\n",
        "# No API key is needed for basic yfinance usage\n",
        "STOCK_SYMBOLS = [\"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\"] # Three NIFTY 50 stocks for NSE.\n",
        "\n",
        "# Google Sheets Configuration\n",
        "GOOGLE_SHEET_ID = '1W8nP1H7oIKwdy7m5dGii0lZcf_cKxn0mPSdzhAddm80' # Replace with your actual Google Sheet ID\n",
        "GOOGLE_SHEET_TRADELOG_WORKSHEET_NAME = 'TradeLog'\n",
        "GOOGLE_SHEET_PNL_WORKSHEET_NAME = 'Summary PnL'\n",
        "TELEGRAM_ALERTS_WORKSHEET_NAME = 'Alerts'\n",
        "\n",
        "# Telegram Configuration\n",
        "TELEGRAM_BOT_TOKEN = 'YOUR_BOT_TOKEN' # Replace with your Telegram Bot Token\n",
        "TELEGRAM_CHAT_ID = 'YOUR_CHAT_ID'     # Replace with your Telegram Chat ID\n",
        "\n",
        "# Google Sheets\n",
        "GOOGLE_SHEET_ID = \"1W8nP1H7oIKwdy7m5dGii0lZcf_cKxn0mPSdzhAddm80\"\n",
        "TRADE_LOG_SHEET_NAME = \"Trade Log\"\n",
        "SUMMARY_PL_SHEET_NAME = \"Summary P&L\"\n",
        "WIN_RATIO_SHEET_NAME = \"Win Ratio\"\n",
        "\n",
        "# Strategy Parameters\n",
        "RSI_PERIOD = 14\n",
        "RSI_BUY_THRESHOLD = 30\n",
        "SHORT_MA_PERIOD = 20 # 20-Day Moving Average\n",
        "LONG_MA_PERIOD = 50  # 50-Day Moving Average\n",
        "\n",
        "# Backtesting Parameters\n",
        "BACKTEST_DURATION_MONTHS = 6\n",
        "\n",
        "# ML Model Parameters\n",
        "FEATURES = ['RSI', 'MACD', 'Volume', 'Close'] # Features for ML model\n",
        "TARGET = 'Next_Day_Movement' # Targets for ML model\n",
        "\n",
        "# Telegram Alerts (Bonus)\n",
        "TELEGRAM_BOT_TOKEN = \"8144019769:AAF-f7tW-XV9URIgJAAFyQgNtE0Tce0naXw\"\n",
        "TELEGRAM_CHAT_ID = \"1463467106\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mU0VgdkQTtP",
        "outputId": "994129b8-178b-4b2b-a6b7-3448fbc81fe1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/config/settings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP LOGGING TO BOTH CONSOLE AND A FILE IN LOGS DIRECTORY"
      ],
      "metadata": {
        "id": "LnqI9HmOR4Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/utils/logger.py\n",
        "# utils/logger.py\n",
        "\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_logging():\n",
        "    \"\"\"Configures logging for the application.\"\"\"\n",
        "    # Adjusted log_dir to be within your mounted Google Drive project structure.\n",
        "    log_dir = '/content/drive/MyDrive/algo_trading_prototype/logs'\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    log_file = os.path.join(log_dir, f\"algo_trading_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO, # Log INFO, WARNING, ERROR, CRITICAL messages\n",
        "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file), # Log to a file\n",
        "            logging.StreamHandler()        # Also print to console\n",
        "        ]\n",
        "    )\n",
        "    # Suppressing verbose logging from libraries to keep console clean\n",
        "    logging.getLogger('requests').setLevel(logging.WARNING)\n",
        "    logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
        "    logging.getLogger('yfinance').setLevel(logging.WARNING)\n",
        "    logging.getLogger('gspread').setLevel(logging.WARNING)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0sF6e_GR3lY",
        "outputId": "9e9a83fd-b626-41c9-8995-3dd877f8aa3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/utils/logger.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLES FETCHING STOCK DATA USING YFINANCE"
      ],
      "metadata": {
        "id": "4_Vh_wcvSvW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py\n",
        "# data/data_fetcher.py\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "from config import settings\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class DataFetcher:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fetch_historical_data(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
        "        try:\n",
        "            df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
        "            if df.empty:\n",
        "                logger.warning(f\"No data fetched for {symbol} between {start_date} and {end_date}.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Ensure index is a clean DatetimeIndex and named 'Date'\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "            df.index.name = 'Date'\n",
        "\n",
        "            # --- CRITICAL FIX FOR YFINANCE COLUMNS (Revised) ---\n",
        "            # Step 1: Flatten MultiIndex columns if they exist.\n",
        "            # This is common, and the format is usually ('ColumnName', 'SymbolSuffix') or ('ColumnName', '')\n",
        "            if isinstance(df.columns, pd.MultiIndex):\n",
        "                # We want just 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'\n",
        "                # Let's extract the first level of the MultiIndex or the full string if it's not a tuple\n",
        "                new_columns = []\n",
        "                for col in df.columns:\n",
        "                    if isinstance(col, tuple):\n",
        "                        # Take the main part (e.g., 'Close' from ('Close', 'RELIANCE.NS'))\n",
        "                        new_columns.append(col[0].strip())\n",
        "                    else:\n",
        "                        new_columns.append(col.strip())\n",
        "                df.columns = new_columns\n",
        "                logger.info(f\"Flattened MultiIndex columns for {symbol}. Raw flattened columns: {df.columns.tolist()}\")\n",
        "\n",
        "            # Step 2: Standardize column names and handle 'Adj Close'\n",
        "            # Convert all column names to standard format (e.g., 'Open', 'Close')\n",
        "            # Use .str.capitalize() on a Series of column names to handle variations like 'open' -> 'Open'\n",
        "            df.columns = df.columns.str.replace(' ', '').str.capitalize() # Remove spaces, then capitalize (e.g., \"Adj Close\" -> \"AdjClose\" -> \"Adjclose\")\n",
        "\n",
        "            # Check for 'Adj Close' (which would now be 'Adjclose' or 'AdjClose')\n",
        "            if 'Adjclose' in df.columns:\n",
        "                df['Close'] = df['Adjclose'] # Use Adjusted Close as the primary 'Close'\n",
        "                df.drop(columns=['Adjclose'], inplace=True)\n",
        "                logger.info(f\"Used 'Adjclose' as 'Close' for {symbol}.\")\n",
        "            elif 'Close' not in df.columns:\n",
        "                 logger.error(f\"Neither 'Close' nor 'Adjclose' found for {symbol}. Available: {df.columns.tolist()}\")\n",
        "                 return pd.DataFrame()\n",
        "\n",
        "\n",
        "            # Ensure only the desired columns are present and in order\n",
        "            required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "            if not all(col in df.columns for col in required_columns):\n",
        "                missing = [col for col in required_columns if col not in df.columns]\n",
        "                logger.error(f\"Missing one or more critical columns ({missing}) after standardization for {symbol}. Available: {df.columns.tolist()}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            df = df[required_columns] # Select the columns in the desired order\n",
        "\n",
        "            logger.info(f\"Successfully fetched and prepared historical data for {symbol}. Final columns: {df.columns.tolist()}\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol} using yfinance: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "# This function must have ZERO indentation\n",
        "def get_historical_data(symbols: list, duration_months: int) -> dict:\n",
        "    \"\"\"\n",
        "    Fetches historical data for multiple symbols for the last 'duration_months' using yfinance.\n",
        "    Parameters:\n",
        "        symbols (list): List of stock ticker symbols.\n",
        "        duration_months (int): Number of months for which to fetch historical data.\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are symbols and values are pandas DataFrames.\n",
        "    \"\"\"\n",
        "    data_fetcher = DataFetcher()\n",
        "    all_data = {}\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=duration_months * 30)\n",
        "\n",
        "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "    for symbol in symbols:\n",
        "        df = data_fetcher.fetch_historical_data(symbol, start_date_str, end_date_str)\n",
        "        if not df.empty:\n",
        "            all_data[symbol] = df\n",
        "    return all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0clOdM0IQ6lD",
        "outputId": "01efb2b1-f956-4778-def2-55a45cb3b60b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTIONS TO CALCULATE TECHNICAL INDICATORS LIKE RSI AND MOVING AVERAGES"
      ],
      "metadata": {
        "id": "dLoj7u1STRdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: strategy/indicators.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/strategy/indicators.py\n",
        "# strategy/indicators.py\n",
        "\n",
        "import pandas as pd\n",
        "import ta # Technical Analysis library\n",
        "\n",
        "def calculate_rsi(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Calculates Relative Strength Index (RSI).\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with 'Close' prices.\n",
        "        window (int): The window period for RSI calculation.\n",
        "    Returns:\n",
        "        pd.Series: A Series containing RSI values.\n",
        "    \"\"\"\n",
        "    return ta.momentum.RSIIndicator(df[\"Close\"].squeeze(), window=window).rsi()\n",
        "\n",
        "def calculate_sma(df: pd.DataFrame, window: int) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Calculates Simple Moving Average (SMA).\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with 'Close' prices.\n",
        "        window (int): The window period for SMA calculation.\n",
        "    Returns:\n",
        "        pd.Series: A Series containing SMA values.\n",
        "    \"\"\"\n",
        "    return ta.trend.SMAIndicator(df[\"Close\"], window=window).sma_indicator()\n",
        "\n",
        "def calculate_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates Moving Average Convergence Divergence (MACD), Signal Line, and MACD Histogram.\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with 'Close' prices.\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'MACD', 'MACD_Signal', and 'MACD_Hist' columns.\n",
        "    \"\"\"\n",
        "    # Fixed: Ensure df[\"Close\"] is explicitly a Series using .squeeze()\n",
        "    macd_indicator = ta.trend.MACD(df[\"Close\"].squeeze()) # <<< ADD .squeeze() here\n",
        "    return pd.DataFrame({\n",
        "        'MACD': macd_indicator.macd(),\n",
        "        'MACD_Signal': macd_indicator.macd_signal(),\n",
        "        'MACD_Hist': macd_indicator.macd_diff()\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPNezTKCSpm7",
        "outputId": "ace9dc85-90dc-496a-86d1-4da9b6188ef7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/strategy/indicators.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTS THE TRADING STRATEGY LOGIC (RSI + Moving Average crossover)"
      ],
      "metadata": {
        "id": "FzRkLo0RTjO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: strategy/trading_strategy.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/strategy/trading_strategy.py\n",
        "# strategy/trading_strategy.py\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "from strategy.indicators import calculate_rsi, calculate_sma\n",
        "from config import settings # Import settings module directly\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TradingStrategy:\n",
        "    def __init__(self):\n",
        "        self.rsi_period = settings.RSI_PERIOD\n",
        "        self.rsi_buy_threshold = settings.RSI_BUY_THRESHOLD\n",
        "        self.short_ma_period = settings.SHORT_MA_PERIOD\n",
        "        self.long_ma_period = settings.LONG_MA_PERIOD\n",
        "\n",
        "    def generate_signals(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Generates buy/sell signals based on RSI and Moving Average Crossover strategy.\n",
        "        Adds 'RSI', 'SMA_short', 'SMA_long', 'Signal' (1=Buy, -1=Sell, 0=Hold), and 'Position' columns.\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): DataFrame with historical OHLCV data.\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with added indicator, signal, and position columns.\n",
        "        \"\"\"\n",
        "        if df.empty:\n",
        "            logger.warning(\"Empty DataFrame provided to generate_signals.\")\n",
        "            return df\n",
        "\n",
        "        # Calculate indicators\n",
        "        df['RSI'] = calculate_rsi(df, self.rsi_period)\n",
        "        df[f'SMA_{self.short_ma_period}'] = calculate_sma(df, self.short_ma_period)\n",
        "        df[f'SMA_{self.long_ma_period}'] = calculate_sma(df, self.long_ma_period)\n",
        "\n",
        "        df['Signal'] = 0 # Default to hold signal\n",
        "        df['Position'] = 0 # 1 for Long, 0 for Flat (no position)\n",
        "\n",
        "        # Drop NaN values introduced by indicator calculations before generating signals\n",
        "        df.dropna(subset=['RSI', f'SMA_{self.short_ma_period}', f'SMA_{self.long_ma_period}'], inplace=True)\n",
        "        if df.empty:\n",
        "            logger.warning(\"DataFrame became empty after dropping NaNs for indicator calculations.\")\n",
        "            return df\n",
        "\n",
        "        # Buy condition: RSI < 30 AND 20-DMA crosses above 50-DMA\n",
        "        # Check current day's MA relationship and previous day's relationship for a crossover\n",
        "        buy_condition = (df['RSI'] < self.rsi_buy_threshold) & \\\n",
        "                        (df[f'SMA_{self.short_ma_period}'] > df[f'SMA_{self.long_ma_period}']) & \\\n",
        "                        (df[f'SMA_{self.short_ma_period}'].shift(1) <= df[f'SMA_{self.long_ma_period}'].shift(1))\n",
        "\n",
        "        # Sell condition: 20-DMA crosses below 50-DMA (as a simple exit)\n",
        "        sell_condition = (df[f'SMA_{self.short_ma_period}'] < df[f'SMA_{self.long_ma_period}']) & \\\n",
        "                         (df[f'SMA_{self.short_ma_period}'].shift(1) >= df[f'SMA_{self.long_ma_period}'].shift(1))\n",
        "\n",
        "        # Apply signals\n",
        "        df.loc[buy_condition, 'Signal'] = 1\n",
        "        df.loc[sell_condition, 'Signal'] = -1\n",
        "\n",
        "        # Determine position based on signals\n",
        "        # This simulates opening a position on a buy signal and closing on a sell signal.\n",
        "        # It's a simplified approach for backtesting.\n",
        "        current_position = 0\n",
        "        position_list = []\n",
        "        for i in range(len(df)):\n",
        "            if df['Signal'].iloc[i] == 1: # Buy signal\n",
        "                current_position = 1 # Go long\n",
        "            elif df['Signal'].iloc[i] == -1: # Sell signal\n",
        "                current_position = 0 # Close position (go flat)\n",
        "            position_list.append(current_position)\n",
        "\n",
        "        df['Position'] = position_list\n",
        "        logger.info(\"Signals generated successfully.\")\n",
        "        return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4kVEa2ZTdx7",
        "outputId": "43abd49c-6a89-40f4-c796-f2b08c0c2ca0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/strategy/trading_strategy.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMULATES TRADING STRATEGY BASED ON HISTORICAL DATA"
      ],
      "metadata": {
        "id": "5jwlAbAvT2hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 9: backtester/backtester.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/backtester/backtester.py\n",
        "# backtester/backtester.py\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "from strategy.trading_strategy import TradingStrategy\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Backtester:\n",
        "    def __init__(self):\n",
        "        self.strategy = TradingStrategy()\n",
        "        self.trade_log = [] # To store details of each trade\n",
        "\n",
        "    def run_backtest(self, symbol: str, historical_data: pd.DataFrame) -> dict:\n",
        "        \"\"\"\n",
        "        Runs a backtest on the given historical data for a symbol.\n",
        "        Simulates trades based on signals and calculates P&L.\n",
        "        Parameters:\n",
        "            symbol (str): Stock ticker symbol.\n",
        "            historical_data (pd.DataFrame): DataFrame with historical OHLCV data.\n",
        "        Returns:\n",
        "            dict: Dictionary containing backtest summary (initial/final capital, total P&L)\n",
        "                  and the detailed trade log. Returns empty dict if backtest cannot run.\n",
        "        \"\"\"\n",
        "        if historical_data.empty:\n",
        "            logger.warning(f\"No historical data provided for backtesting {symbol}.\")\n",
        "            return {}\n",
        "\n",
        "        df = historical_data.copy()\n",
        "        df = self.strategy.generate_signals(df)\n",
        "\n",
        "        # Filter out NaN rows that resulted from indicator calculations for cleaner iteration\n",
        "        df.dropna(subset=['RSI', 'Signal', 'Position'], inplace=True)\n",
        "        if df.empty:\n",
        "            logger.warning(f\"Data for {symbol} became empty after dropping NaNs for signals. Cannot backtest.\")\n",
        "            return {}\n",
        "\n",
        "        initial_capital = 100000 # Example initial capital\n",
        "        current_capital = initial_capital\n",
        "        position_open = False\n",
        "        buy_price = 0\n",
        "        shares_held = 0\n",
        "\n",
        "        # Reset trade_log for each backtest run\n",
        "        self.trade_log = []\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            date = df.index[i]\n",
        "            close_price = df['Close'].iloc[i]\n",
        "            signal = df['Signal'].iloc[i]\n",
        "            current_position_status = df['Position'].iloc[i] # Current position from strategy\n",
        "\n",
        "            # Execute buy trade\n",
        "            if signal == 1 and not position_open: # Buy signal and no open position\n",
        "                shares_to_buy = int(current_capital / close_price) # Buy as many shares as possible\n",
        "                if shares_to_buy > 0:\n",
        "                    buy_price = close_price\n",
        "                    shares_held = shares_to_buy\n",
        "                    current_capital -= (shares_held * buy_price) # Deduct cost\n",
        "                    position_open = True\n",
        "                    self.trade_log.append({\n",
        "                        'Symbol': symbol,\n",
        "                        'Date': date.strftime('%Y-%m-%d'),\n",
        "                        'Type': 'BUY',\n",
        "                        'Price': round(buy_price, 2),\n",
        "                        'Shares': shares_held,\n",
        "                        'Capital_After_Trade': round(current_capital, 2),\n",
        "                        'P&L': 0.0 # P&L is realized on sell\n",
        "                    })\n",
        "                    logger.info(f\"{symbol} - {date.strftime('%Y-%m-%d')}: BUY at {buy_price:.2f} (Shares: {shares_held})\")\n",
        "\n",
        "            # Execute sell trade\n",
        "            elif signal == -1 and position_open: # Sell signal and there is an open position\n",
        "                sell_price = close_price\n",
        "                pnl = (sell_price - buy_price) * shares_held\n",
        "                current_capital += (shares_held * sell_price) # Add proceeds\n",
        "                position_open = False\n",
        "                self.trade_log.append({\n",
        "                    'Symbol': symbol,\n",
        "                    'Date': date.strftime('%Y-%m-%d'),\n",
        "                    'Type': 'SELL',\n",
        "                    'Price': round(sell_price, 2),\n",
        "                    'Shares': shares_held,\n",
        "                    'Capital_After_Trade': round(current_capital, 2),\n",
        "                    'P&L': round(pnl, 2)\n",
        "                })\n",
        "                logger.info(f\"{symbol} - {date.strftime('%Y-%m-%d')}: SELL at {sell_price:.2f} (P&L: {pnl:.2f})\")\n",
        "                buy_price = 0 # Reset buy price\n",
        "                shares_held = 0 # Reset shares held\n",
        "\n",
        "        # If a position is still open at the end of the backtest, close it forcibly\n",
        "        if position_open:\n",
        "            sell_price = df['Close'].iloc[-1]\n",
        "            pnl = (sell_price - buy_price) * shares_held\n",
        "            current_capital += (shares_held * sell_price)\n",
        "            self.trade_log.append({\n",
        "                'Symbol': symbol,\n",
        "                'Date': df.index[-1].strftime('%Y-%m-%d'),\n",
        "                'Type': 'SELL (Forced Exit)', # Indicate a forced exit at end of backtest period\n",
        "                'Price': round(sell_price, 2),\n",
        "                'Shares': shares_held,\n",
        "                'Capital_After_Trade': round(current_capital, 2),\n",
        "                'P&L': round(pnl, 2)\n",
        "            })\n",
        "            logger.info(f\"{symbol} - Forced SELL at {sell_price:.2f} (P&L: {pnl:.2f}) at end of backtest.\")\n",
        "\n",
        "        total_pnl = current_capital - initial_capital\n",
        "        logger.info(f\"Backtest for {symbol} completed. Total P&L: {total_pnl:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'symbol': symbol,\n",
        "            'initial_capital': initial_capital,\n",
        "            'final_capital': current_capital,\n",
        "            'total_pnl': total_pnl,\n",
        "            'trade_log': pd.DataFrame(self.trade_log) # Convert to DataFrame for easier handling\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacWdbGATvov",
        "outputId": "3cc03a9a-eb42-4f47-907d-1fc2907b656c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/backtester/backtester.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTS THE MACHINE LEARNING MODEL FOR NEXT DAY MOVEMENT PREDICTION"
      ],
      "metadata": {
        "id": "v38kah48hg1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/analytics/ml_predictor.py\n",
        "# analytics/ml_predictor.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import logging\n",
        "from strategy.indicators import calculate_rsi, calculate_macd\n",
        "from config import settings\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class MLPredictor:\n",
        "    def __init__(self, model_type: str = 'decision_tree'):\n",
        "        \"\"\"\n",
        "        Initializes the ML Predictor with a specified model type.\n",
        "        Parameters:\n",
        "            model_type (str): 'decision_tree' or 'logistic_regression'.\n",
        "        \"\"\"\n",
        "        if model_type == 'decision_tree':\n",
        "            self.model = DecisionTreeClassifier(random_state=42)\n",
        "        elif model_type == 'logistic_regression':\n",
        "            self.model = LogisticRegression(random_state=42, solver='liblinear')\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported model_type. Choose 'decision_tree' or 'logistic_regression'.\")\n",
        "        self.trained = False # Flag to check if model has been trained\n",
        "\n",
        "\n",
        "    def prepare_data_for_ml(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        # Calculate features\n",
        "        df['RSI'] = calculate_rsi(df, window=settings.RSI_PERIOD)\n",
        "        # Ensure MACD df has a matching index to the main df before merging\n",
        "        macd_df = calculate_macd(df)\n",
        "\n",
        "        # Use pd.merge on the index (which is 'Date')\n",
        "        # Assuming both df and macd_df have a clean DatetimeIndex\n",
        "        df = pd.merge(df, macd_df, left_index=True, right_index=True, how='inner') # Use inner to keep only common dates\n",
        "\n",
        "\n",
        "        # Calculate next-day close movement as target (1 for Up, 0 for Down/No Change)\n",
        "        # Shift(-1) means the close price of the *next* row\n",
        "        df['Next_Day_Close'] = df['Close'].shift(-1)\n",
        "        # Target: 1 if next day's close is higher, 0 otherwise\n",
        "        df['Next_Day_Movement'] = (df['Next_Day_Close'] > df['Close']).astype(int)\n",
        "\n",
        "        # Drop rows with NaN values (due to indicator calculation or Next_Day_Close for last row)\n",
        "        df.dropna(subset=settings.FEATURES + ['Next_Day_Movement'], inplace=True)\n",
        "        return df\n",
        "\n",
        "    def train_model(self, df: pd.DataFrame, features: list, target: str):\n",
        "        \"\"\"\n",
        "        Trains the ML model and evaluates its performance.\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): Prepared DataFrame with features and target.\n",
        "            features (list): List of column names to use as features.\n",
        "            target (str): Name of the target column.\n",
        "        Returns:\n",
        "            tuple: (accuracy, classification_report_string). Returns (0.0, \"\") if training fails.\n",
        "        \"\"\"\n",
        "        if df.empty or not all(col in df.columns for col in features + [target]):\n",
        "            logger.warning(\"Insufficient data or missing columns for ML training.\")\n",
        "            self.trained = False\n",
        "            return 0.0, \"\"\n",
        "\n",
        "        X = df[features]\n",
        "        y = df[target]\n",
        "\n",
        "        # Handle cases where only one class is present in the target variable\n",
        "        if len(y.unique()) < 2:\n",
        "            logger.warning(f\"Only one class present in target variable for ML training (symbol has no 'Up' or 'Down' movements in data). Skipping training.\")\n",
        "            self.trained = False\n",
        "            return 0.0, \"Only one class in target\"\n",
        "\n",
        "        try:\n",
        "            # Stratify ensures that the train/test split maintains the proportion of classes\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        except ValueError as e:\n",
        "            logger.warning(f\"Could not split data for ML training due to: {e}. Check data balance or size.\")\n",
        "            self.trained = False\n",
        "            return 0.0, str(e)\n",
        "\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        # zero_division=0 prevents warnings when a class has no predicted samples\n",
        "        report = classification_report(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        logger.info(f\"ML Model Training Complete (Model: {type(self.model).__name__}):\")\n",
        "        logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
        "        logger.info(f\"Classification Report:\\n{report}\")\n",
        "        self.trained = True\n",
        "        return accuracy, report\n",
        "\n",
        "    def predict_next_day_movement(self, latest_data_df: pd.DataFrame, features: list) -> int:\n",
        "        \"\"\"\n",
        "        Predicts the next day's movement (1 for Up, 0 for Down/No Change) based on the trained model.\n",
        "        `latest_data_df` should contain enough historical rows to calculate required indicators\n",
        "        for the *last* data point.\n",
        "        Parameters:\n",
        "            latest_data_df (pd.DataFrame): DataFrame containing recent historical OHLCV data.\n",
        "                                           Should include enough rows to calculate all features.\n",
        "            features (list): List of feature column names used during training.\n",
        "        Returns:\n",
        "            int: 1 for 'Up', 0 for 'Down/No Change', -1 if prediction cannot be made (e.g., not trained, no data).\n",
        "        \"\"\"\n",
        "        if not self.trained:\n",
        "            logger.warning(\"ML model is not trained. Cannot make prediction.\")\n",
        "            return -1\n",
        "\n",
        "        if latest_data_df.empty:\n",
        "            logger.warning(\"Empty DataFrame provided for ML prediction.\")\n",
        "            return -1\n",
        "\n",
        "        # Prepare the data to get the latest features, similar to training data prep\n",
        "        processed_df = self.prepare_data_for_ml(latest_data_df.copy())\n",
        "        if processed_df.empty:\n",
        "            logger.warning(\"Could not process latest data for prediction after feature engineering.\")\n",
        "            return -1\n",
        "\n",
        "        # The last row of `processed_df` contains the latest calculated features\n",
        "        # and its 'Next_Day_Movement' would be NaN (which is fine for prediction input)\n",
        "        try:\n",
        "            latest_features_row = processed_df[features].iloc[-1]\n",
        "            # Reshape for prediction (sklearn expects 2D array, even for a single sample)\n",
        "            prediction_input = latest_features_row.to_frame().T\n",
        "            prediction = self.model.predict(prediction_input)[0]\n",
        "            logger.info(f\"Next day movement prediction: {'Up' if prediction == 1 else 'Down/No Change'}\")\n",
        "            return int(prediction) # You had a stray comment/code here, moved this line up\n",
        "        except IndexError:\n",
        "            logger.warning(\"Not enough data points in processed_df for prediction after feature engineering.\")\n",
        "            return -1\n",
        "        except KeyError as e:\n",
        "            logger.warning(f\"Missing feature for prediction: {e}. Check FEATURES in settings.py and data preparation.\")\n",
        "            return -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpi8UXWfT0pv",
        "outputId": "7b557fb9-0dfd-4f46-ebf8-a582fd211c12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/analytics/ml_predictor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MANAGES INTERACTIONS WITH GOOGLE SHEETS"
      ],
      "metadata": {
        "id": "LZyv5x8Mh2zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from google.oauth2.service_account import Credentials\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GoogleSheetsManager:\n",
        "    def __init__(self, creds_file):\n",
        "        self.creds_file = creds_file\n",
        "        self.client = None\n",
        "\n",
        "    def authenticate(self):\n",
        "        try:\n",
        "            scope = [\n",
        "                \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "                \"https://www.googleapis.com/auth/drive\"\n",
        "            ]\n",
        "            creds = Credentials.from_service_account_file(self.creds_file, scopes=scope)\n",
        "            self.client = gspread.authorize(creds)\n",
        "            logger.info(\"✅ Google Sheets authentication successful.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Error authenticating with Google Sheets: {e}\")\n",
        "            raise\n",
        "\n",
        "    def log_trade(self, sheet_name, trade_data):\n",
        "        try:\n",
        "            sheet = self.client.open(sheet_name).sheet1\n",
        "            sheet.append_row(trade_data)\n",
        "            logger.info(f\"📄 Trade logged in sheet '{sheet_name}'.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Error logging trade to Google Sheets: {e}\")\n",
        "\n",
        "    def update_summary_pnl(self, sheet_name, worksheet_name, pnl_results):\n",
        "        \"\"\"\n",
        "        Updates or creates a worksheet with total PnL summary.\n",
        "\n",
        "        Args:\n",
        "            sheet_name (str): Google Sheet name\n",
        "            worksheet_name (str): Worksheet tab name\n",
        "            pnl_results (dict): {symbol: total_pnl}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            spreadsheet = self.client.open(sheet_name)\n",
        "\n",
        "            # Create worksheet if it doesn't exist\n",
        "            try:\n",
        "                worksheet = spreadsheet.worksheet(worksheet_name)\n",
        "            except gspread.WorksheetNotFound:\n",
        "                worksheet = spreadsheet.add_worksheet(title=worksheet_name, rows=\"100\", cols=\"2\")\n",
        "\n",
        "            # Prepare data for update\n",
        "            data_to_write = [['Symbol', 'Total PnL']]\n",
        "            for symbol, pnl in pnl_results.items():\n",
        "                data_to_write.append([symbol, round(pnl, 2)])  # Append symbol and rounded PnL\n",
        "\n",
        "            # Write the data to the sheet starting at cell A1\n",
        "            worksheet.update('A1', data_to_write)\n",
        "            logger.info(f\"📊 Summary PnL updated successfully in worksheet '{worksheet_name}'.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Error updating Summary PnL: {e}\")\n"
      ],
      "metadata": {
        "id": "a355eEPdh02M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLES TELEGRAM MESSAGES"
      ],
      "metadata": {
        "id": "5VbUITMXiVbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: utils/alerts.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/utils/alerts.py\n",
        "# utils/alerts.py\n",
        "\n",
        "import requests\n",
        "import logging\n",
        "from config import settings # Import settings module directly\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def send_telegram_message(message: str):\n",
        "    \"\"\"\n",
        "    Sends a message to a specified Telegram chat.\n",
        "    Requires TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID from config/settings.py.\n",
        "    Parameters:\n",
        "        message (str): The text message to send.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        bot_token = settings.TELEGRAM_BOT_TOKEN\n",
        "        chat_id = settings.TELEGRAM_CHAT_ID\n",
        "    except AttributeError:\n",
        "        logger.error(\"Telegram bot token or chat ID not found in settings.py. Skipping Telegram alert.\")\n",
        "        return\n",
        "\n",
        "    if not bot_token or not chat_id:\n",
        "        logger.warning(\"Telegram BOT_TOKEN or CHAT_ID is not configured. Skipping alert.\")\n",
        "        return\n",
        "\n",
        "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
        "    payload = {\n",
        "        \"chat_id\": chat_id,\n",
        "        \"text\": message,\n",
        "        \"parse_mode\": \"Markdown\" # Allows basic markdown formatting in message\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(url, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        logger.info(\"Telegram message sent successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logger.error(f\"Error sending Telegram message: {e}\")"
      ],
      "metadata": {
        "id": "mIYasGnZiKRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01ad5ad-4f43-4aed-a022-c615931839ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/utils/alerts.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLACEHOLDER FOR THIS PROTOTYPE"
      ],
      "metadata": {
        "id": "WTkuaMJRklL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: analytics/portfolio_analytics.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/analytics/portfolio_analytics.py\n",
        "# analytics/portfolio_analytics.py\n",
        "\n",
        "# This file is a placeholder. Its functionalities (P&L, Win Ratio)\n",
        "# are integrated directly into Backtester and GoogleSheetsManager for simplicity.\n",
        "# For more complex analytics (e.g., Sharpe Ratio, Max Drawdown), you would\n",
        "# implement them here."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2COS9PskbBx",
        "outputId": "3a908373-2b37-4791-b177-68e9ed17a636"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/analytics/portfolio_analytics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: main.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/main.py\n",
        "# main.py\n",
        "\n",
        "import logging\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Define the project root directly within main.py\n",
        "# This ensures that main.py itself knows where the root of your project is,\n",
        "# regardless of how it's executed, which helps Python find your modules.\n",
        "project_root = '/content/drive/MyDrive/algo_trading_prototype'\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "    # Note: If you modify this or any other module, you might need to\n",
        "    # restart your Colab runtime to ensure changes are picked up due to Python's module caching.\n",
        "\n",
        "# Now, import modules using their top-level package names relative to project_root\n",
        "from config import settings\n",
        "from utils import logger\n",
        "from data import data_fetcher\n",
        "from backtester import backtester\n",
        "from analytics import ml_predictor\n",
        "from sheets import google_sheets_manager\n",
        "from utils import alerts # Bonus: Telegram alerts\n",
        "\n",
        "# Setup logging. This needs to be called to configure loggers globally.\n",
        "logger.setup_logging()\n",
        "main_logger = logging.getLogger(__name__) # Get a specific logger for the main script\n",
        "\n",
        "def run_algo_prototype():\n",
        "    \"\"\"\n",
        "    Main function to run the algo-trading prototype.\n",
        "    Orchestrates data fetching, strategy application, backtesting,\n",
        "    ML prediction, and Google Sheets logging.\n",
        "    \"\"\"\n",
        "    main_logger.info(\"Starting Algo-Trading Prototype...\")\n",
        "\n",
        "    # Initialize components\n",
        "    sheets_manager = google_sheets_manager.GoogleSheetsManager()\n",
        "    backtester_instance = backtester.Backtester()\n",
        "    ml_predictor_instance = ml_predictor.MLPredictor(model_type='decision_tree') # Can be 'logistic_regression'\n",
        "\n",
        "    all_trade_logs = pd.DataFrame() # To aggregate trade logs from all symbols\n",
        "    symbol_pnl_results = {} # To store P&L summary per symbol\n",
        "    ml_accuracies = {} # To store ML model accuracies per symbol\n",
        "\n",
        "    # --- 1. Data Ingestion & ML Model Training ---\n",
        "    main_logger.info(f\"Fetching historical data for {settings.STOCK_SYMBOLS} for {settings.BACKTEST_DURATION_MONTHS} months...\")\n",
        "    historical_data = data_fetcher.get_historical_data(settings.STOCK_SYMBOLS, settings.BACKTEST_DURATION_MONTHS)\n",
        "\n",
        "    if not historical_data:\n",
        "        main_logger.error(\"No historical data fetched. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Train ML model for each stock using its historical data\n",
        "    main_logger.info(\"Preparing data and training ML model for each stock...\")\n",
        "    for symbol, df in historical_data.items():\n",
        "        if not df.empty:\n",
        "            ml_data = ml_predictor_instance.prepare_data_for_ml(df.copy())\n",
        "            if not ml_data.empty:\n",
        "                accuracy, _ = ml_predictor_instance.train_model(ml_data, settings.FEATURES, settings.TARGET)\n",
        "                ml_accuracies[symbol] = accuracy\n",
        "            else:\n",
        "                main_logger.warning(f\"Could not prepare ML data for {symbol}.\")\n",
        "        else:\n",
        "            main_logger.warning(f\"No data for {symbol} to train ML model.\")\n",
        "\n",
        "    main_logger.info(f\"ML Model Accuracies: {ml_accuracies}\")\n",
        "\n",
        "    # --- 2. Run Backtest for each stock ---\n",
        "    for symbol, df in historical_data.items():\n",
        "        if df.empty:\n",
        "            main_logger.warning(f\"Skipping backtest for {symbol} due to no data.\")\n",
        "            continue\n",
        "\n",
        "        main_logger.info(f\"Running backtest for {symbol}...\")\n",
        "        results = backtester_instance.run_backtest(symbol, df.copy())\n",
        "        if results:\n",
        "            symbol_pnl_results[symbol] = {\n",
        "                'initial_capital': results['initial_capital'],\n",
        "                'final_capital': results['final_capital'],\n",
        "                'total_pnl': results['total_pnl']\n",
        "            }\n",
        "            if not results['trade_log'].empty:\n",
        "                # Concatenate trade logs from each symbol into one DataFrame\n",
        "                all_trade_logs = pd.concat([all_trade_logs, results['trade_log']], ignore_index=True)\n",
        "        else:\n",
        "            main_logger.warning(f\"Backtest for {symbol} yielded no results.\")\n",
        "\n",
        "    # --- 3. Google Sheets Automation ---\n",
        "    # Log all aggregated trade signals\n",
        "    if not all_trade_logs.empty:\n",
        "        main_logger.info(\"Logging trade signals to Google Sheets...\")\n",
        "        sheets_manager.log_trade_signals(all_trade_logs)\n",
        "        # Update win ratio based on all logs\n",
        "        sheets_manager.update_win_ratio(all_trade_logs)\n",
        "    else:\n",
        "        main_logger.info(\"No trade logs to write to Google Sheets.\")\n",
        "\n",
        "    # Update summary P&L\n",
        "    if symbol_pnl_results:\n",
        "        main_logger.info(\"Updating summary P&L in Google Sheets...\")\n",
        "        sheets_manager.update_summary_pnl(symbol_pnl_results)\n",
        "    else:\n",
        "        main_logger.info(\"No summary P&L to write to Google Sheets.\")\n",
        "\n",
        "    # --- 4. Generate Current Buy/Sell Signals and ML Predictions ---\n",
        "    main_logger.info(\"Generating current (latest date) buy/sell signals and ML predictions...\")\n",
        "    for symbol, df in historical_data.items():\n",
        "        if df.empty:\n",
        "            main_logger.warning(f\"Cannot generate signal for {symbol}: no data.\")\n",
        "            continue\n",
        "\n",
        "        # Get enough historical data points to calculate all indicators for the latest day\n",
        "        required_rows_for_indicators = max(settings.RSI_PERIOD, settings.SHORT_MA_PERIOD, settings.LONG_MA_PERIOD) + 1 # +1 for current day's signal\n",
        "        latest_data_for_signal = df.tail(required_rows_for_indicators).copy()\n",
        "\n",
        "        if latest_data_for_signal.empty:\n",
        "            main_logger.warning(f\"Not enough recent data for {symbol} to generate current signal after indicator calculation.\")\n",
        "            continue\n",
        "\n",
        "        # Re-run strategy on the latest data to get the current day's signal\n",
        "        processed_latest_data = backtester_instance.strategy.generate_signals(latest_data_for_signal)\n",
        "\n",
        "        # Check if the last row (current day) has valid signal/data\n",
        "        if processed_latest_data.empty or processed_latest_data.iloc[-1].isnull().any():\n",
        "            main_logger.warning(f\"Could not generate clean signal for {symbol} for the latest date after processing.\")\n",
        "            current_signal = 0 # Default to hold if signal is unreliable\n",
        "            current_close = df['Close'].iloc[-1] if not df.empty else 0\n",
        "            current_date = df.index[-1].strftime('%Y-%m-%d') if not df.empty else \"N/A\"\n",
        "        else:\n",
        "            current_signal = processed_latest_data['Signal'].iloc[-1]\n",
        "            current_close = processed_latest_data['Close'].iloc[-1]\n",
        "            current_date = processed_latest_data.index[-1].strftime('%Y-%m-%d')\n",
        "\n",
        "        signal_type = \"HOLD\"\n",
        "        if current_signal == 1:\n",
        "            signal_type = \"BUY\"\n",
        "        elif current_signal == -1:\n",
        "            signal_type = \"SELL\"\n",
        "\n",
        "        main_logger.info(f\"[{symbol}] Latest Strategy Signal ({current_date}): {signal_type} at {current_close:.2f}\")\n",
        "\n",
        "        # ML prediction for next day movement\n",
        "        # Need enough data points for ML features (RSI, MACD, Volume) for the current day\n",
        "        # `prepare_data_for_ml` handles dropping NaNs, so pass a sufficient window of recent data\n",
        "        ml_prediction_input_data = df.tail(max(settings.RSI_PERIOD, 26) + 2).copy() # MACD needs up to 26 periods + 1 for next day shift\n",
        "        if not ml_prediction_input_data.empty and ml_predictor_instance.trained:\n",
        "            next_day_pred = ml_predictor_instance.predict_next_day_movement(ml_prediction_input_data, settings.FEATURES)\n",
        "            ml_pred_text = \"Up\" if next_day_pred == 1 else (\"Down/No Change\" if next_day_pred == 0 else \"N/A - Prediction Failed\")\n",
        "            main_logger.info(f\"[{symbol}] Next Day ML Prediction: {ml_pred_text}\")\n",
        "        else:\n",
        "            ml_pred_text = \"N/A - Model Not Trained or Insufficient Data\"\n",
        "            main_logger.warning(f\"[{symbol}] {ml_pred_text}\")\n",
        "\n",
        "        # Bonus: Telegram Alert Integration\n",
        "        if current_signal != 0 or next_day_pred != -1: # Alert for strategy signals or if ML made a valid prediction\n",
        "            alert_message = sheets_manager.get_signal_alerts(symbol, current_date, signal_type, current_close)\n",
        "            alert_message += f\"\\nML Prediction (Next Day): {ml_pred_text}\"\n",
        "            alerts.send_telegram_message(alert_message)\n",
        "\n",
        "    main_logger.info(\"Algo-Trading Prototype finished.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_algo_prototype()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jna6aUWBkkZb",
        "outputId": "6eb87eb4-27c2-4210-ae88-0050a7585639"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO RUN THE MAIN FILE"
      ],
      "metadata": {
        "id": "3LuAxRfmm5pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute main.py\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Define your project root in Google Drive\n",
        "project_root = '/content/drive/MyDrive/algo_trading_prototype'\n",
        "\n",
        "# Change the current working directory to the project root\n",
        "# This is generally good practice when running a main script from a package.\n",
        "os.chdir(project_root)\n",
        "print(f\"Changed current working directory to: {os.getcwd()}\")\n",
        "\n",
        "# Run your main script.\n",
        "# Because sys.path is handled within main.py, it should now find its modules.\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJrmhP6Ik53D",
        "outputId": "1059aaed-228f-4c28-a6cb-5257f0a027e9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed current working directory to: /content/drive/MyDrive/algo_trading_prototype\n",
            "2025-08-10 04:04:47,905 - __main__ - INFO - Starting Algo-Trading Prototype...\n",
            "2025-08-10 04:04:47,907 - sheets.google_sheets_manager - ERROR - FATAL: credentials.json NOT FOUND at /content/drive/MyDrive/algo_trading_prototype/credentials.json\n",
            "2025-08-10 04:04:47,909 - sheets.google_sheets_manager - ERROR - Error: credentials.json not found at /content/drive/MyDrive/algo_trading_prototype/credentials.json\n",
            "Please ensure your 'credentials.json' is correctly placed and named.\n",
            "2025-08-10 04:04:47,911 - __main__ - INFO - Fetching historical data for ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS'] for 6 months...\n",
            "/content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py:16: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
            "2025-08-10 04:04:48,493 - data.data_fetcher - INFO - Flattened MultiIndex columns for RELIANCE.NS. Raw flattened columns: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
            "2025-08-10 04:04:48,495 - data.data_fetcher - INFO - Successfully fetched and prepared historical data for RELIANCE.NS. Final columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
            "/content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py:16: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
            "2025-08-10 04:04:48,783 - data.data_fetcher - INFO - Flattened MultiIndex columns for TCS.NS. Raw flattened columns: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
            "2025-08-10 04:04:48,785 - data.data_fetcher - INFO - Successfully fetched and prepared historical data for TCS.NS. Final columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
            "/content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py:16: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
            "2025-08-10 04:04:49,012 - data.data_fetcher - INFO - Flattened MultiIndex columns for HDFCBANK.NS. Raw flattened columns: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
            "2025-08-10 04:04:49,014 - data.data_fetcher - INFO - Successfully fetched and prepared historical data for HDFCBANK.NS. Final columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
            "2025-08-10 04:04:49,014 - __main__ - INFO - Preparing data and training ML model for each stock...\n",
            "2025-08-10 04:04:49,047 - analytics.ml_predictor - INFO - ML Model Training Complete (Model: DecisionTreeClassifier):\n",
            "2025-08-10 04:04:49,048 - analytics.ml_predictor - INFO - Accuracy: 0.3000\n",
            "2025-08-10 04:04:49,048 - analytics.ml_predictor - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.20      0.22        10\n",
            "           1       0.33      0.40      0.36        10\n",
            "\n",
            "    accuracy                           0.30        20\n",
            "   macro avg       0.29      0.30      0.29        20\n",
            "weighted avg       0.29      0.30      0.29        20\n",
            "\n",
            "2025-08-10 04:04:49,074 - analytics.ml_predictor - INFO - ML Model Training Complete (Model: DecisionTreeClassifier):\n",
            "2025-08-10 04:04:49,074 - analytics.ml_predictor - INFO - Accuracy: 0.7000\n",
            "2025-08-10 04:04:49,074 - analytics.ml_predictor - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        12\n",
            "           1       0.60      0.75      0.67         8\n",
            "\n",
            "    accuracy                           0.70        20\n",
            "   macro avg       0.70      0.71      0.70        20\n",
            "weighted avg       0.72      0.70      0.70        20\n",
            "\n",
            "2025-08-10 04:04:49,096 - analytics.ml_predictor - INFO - ML Model Training Complete (Model: DecisionTreeClassifier):\n",
            "2025-08-10 04:04:49,096 - analytics.ml_predictor - INFO - Accuracy: 0.4500\n",
            "2025-08-10 04:04:49,096 - analytics.ml_predictor - INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.56      0.48         9\n",
            "           1       0.50      0.36      0.42        11\n",
            "\n",
            "    accuracy                           0.45        20\n",
            "   macro avg       0.46      0.46      0.45        20\n",
            "weighted avg       0.46      0.45      0.45        20\n",
            "\n",
            "2025-08-10 04:04:49,096 - __main__ - INFO - ML Model Accuracies: {'RELIANCE.NS': 0.3, 'TCS.NS': 0.7, 'HDFCBANK.NS': 0.45}\n",
            "2025-08-10 04:04:49,097 - __main__ - INFO - Running backtest for RELIANCE.NS...\n",
            "2025-08-10 04:04:49,108 - strategy.trading_strategy - INFO - Signals generated successfully.\n",
            "2025-08-10 04:04:49,112 - backtester.backtester - INFO - Backtest for RELIANCE.NS completed. Total P&L: 0.00\n",
            "2025-08-10 04:04:49,113 - __main__ - INFO - Running backtest for TCS.NS...\n",
            "2025-08-10 04:04:49,120 - strategy.trading_strategy - INFO - Signals generated successfully.\n",
            "2025-08-10 04:04:49,124 - backtester.backtester - INFO - Backtest for TCS.NS completed. Total P&L: 0.00\n",
            "2025-08-10 04:04:49,125 - __main__ - INFO - Running backtest for HDFCBANK.NS...\n",
            "2025-08-10 04:04:49,132 - strategy.trading_strategy - INFO - Signals generated successfully.\n",
            "2025-08-10 04:04:49,136 - backtester.backtester - INFO - Backtest for HDFCBANK.NS completed. Total P&L: 0.00\n",
            "2025-08-10 04:04:49,137 - __main__ - INFO - No trade logs to write to Google Sheets.\n",
            "2025-08-10 04:04:49,137 - __main__ - INFO - Updating summary P&L in Google Sheets...\n",
            "2025-08-10 04:04:49,137 - sheets.google_sheets_manager - WARNING - Google Sheets connection not established. Cannot update summary P&L.\n",
            "2025-08-10 04:04:49,138 - __main__ - INFO - Generating current (latest date) buy/sell signals and ML predictions...\n",
            "2025-08-10 04:04:49,144 - strategy.trading_strategy - INFO - Signals generated successfully.\n",
            "2025-08-10 04:04:49,145 - __main__ - INFO - [RELIANCE.NS] Latest Strategy Signal (2025-08-08): HOLD at 1367.80\n",
            "2025-08-10 04:04:49,153 - analytics.ml_predictor - INFO - Next day movement prediction: Down/No Change\n",
            "2025-08-10 04:04:49,154 - __main__ - INFO - [RELIANCE.NS] Next Day ML Prediction: Down/No Change\n",
            "2025-08-10 04:04:49,154 - sheets.google_sheets_manager - WARNING - Google Sheets connection not established. Cannot fetch alert configurations.\n",
            "2025-08-10 04:04:49,708 - utils.alerts - INFO - Telegram message sent successfully.\n",
            "2025-08-10 04:04:49,718 - strategy.trading_strategy - INFO - Signals generated successfully.\n",
            "2025-08-10 04:04:49,719 - __main__ - INFO - [TCS.NS] Latest Strategy Signal (2025-08-08): HOLD at 3036.40\n",
            "2025-08-10 04:04:49,730 - analytics.ml_predictor - INFO - Next day movement prediction: Down/No Change\n",
            "2025-08-10 04:04:49,731 - __main__ - INFO - [TCS.NS] Next Day ML Prediction: Down/No Change\n",
            "2025-08-10 04:04:49,731 - sheets.google_sheets_manager - WARNING - Google Sheets connection not established. Cannot fetch alert configurations.\n",
            "2025-08-10 04:04:50,269 - utils.alerts - INFO - Telegram message sent successfully.\n",
            "2025-08-10 04:04:50,328 - strategy.trading_strategy - INFO - Signals generated successfully.\n",
            "2025-08-10 04:04:50,329 - __main__ - INFO - [HDFCBANK.NS] Latest Strategy Signal (2025-08-08): HOLD at 1973.90\n",
            "2025-08-10 04:04:50,371 - analytics.ml_predictor - INFO - Next day movement prediction: Down/No Change\n",
            "2025-08-10 04:04:50,371 - __main__ - INFO - [HDFCBANK.NS] Next Day ML Prediction: Down/No Change\n",
            "2025-08-10 04:04:50,371 - sheets.google_sheets_manager - WARNING - Google Sheets connection not established. Cannot fetch alert configurations.\n",
            "2025-08-10 04:04:50,905 - utils.alerts - INFO - Telegram message sent successfully.\n",
            "2025-08-10 04:04:50,905 - __main__ - INFO - Algo-Trading Prototype finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-BICD5C5mqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}